{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93b53511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef8484b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_diabetes(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec0e9dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2645d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990749, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06833155, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286131, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04688253,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452873, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00422151,  0.00306441]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f4f042e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca734b7",
   "metadata": {},
   "source": [
    "### Using Sklearn's Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3aee402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4526027629719195"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(xtrain, ytrain)\n",
    "ypred = lr.predict(xtest)\n",
    "r2_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede067d3",
   "metadata": {},
   "source": [
    "### Implementing our own Multiple LR class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6428833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR :\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, xtrain, ytrain):\n",
    "        # betas = (XtX)^-1 XtY\n",
    "        xtrain = np.insert(np.array(xtrain),0, 1, axis = 1)\n",
    "        betas = np.linalg.inv(np.dot(xtrain.T, xtrain)).dot(xtrain.T).dot(ytrain)\n",
    "        self.coef_ = betas[1:]\n",
    "        self.intercept_ = betas[0]\n",
    "        #print(betas.shape) \n",
    "    \n",
    "    def predict(self, xtest):\n",
    "        #print(np.dot(xtest, self.coef_ ).shape)\n",
    "        return self.intercept_ + np.dot(xtest, self.coef_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00c36326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4526027629719197"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LR()\n",
    "lr.fit(xtrain, ytrain)\n",
    "pred = lr.predict(xtest)\n",
    "r2_score(ytest, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecdb0235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  7.07687525e-02,  5.06801187e-02, ...,\n",
       "         3.43088589e-02,  2.73640491e-02, -1.07769750e-03],\n",
       "       [ 1.00000000e+00, -9.14709343e-03,  5.06801187e-02, ...,\n",
       "         7.12099798e-02,  2.72478149e-04,  1.96328371e-02],\n",
       "       [ 1.00000000e+00,  5.38306037e-03, -4.46416365e-02, ...,\n",
       "        -2.59226200e-03,  1.70360713e-02, -1.35040182e-02],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  3.08108295e-02, -4.46416365e-02, ...,\n",
       "        -3.94933829e-02, -1.09032507e-02, -1.07769750e-03],\n",
       "       [ 1.00000000e+00, -1.27796319e-02, -4.46416365e-02, ...,\n",
       "        -2.59226200e-03, -3.84597173e-02, -3.83566597e-02],\n",
       "       [ 1.00000000e+00, -9.26954778e-02, -4.46416365e-02, ...,\n",
       "        -3.94933829e-02, -5.14218980e-03, -1.07769750e-03]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(xtrain,0, 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f74a70b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  37.90402135, -241.96436231,  542.42875852,  347.70384391,\n",
       "       -931.48884588,  518.06227698,  163.41998299,  275.31790158,\n",
       "        736.1988589 ,   48.67065743])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b353bd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.34560453986"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1621583e",
   "metadata": {},
   "source": [
    "### Checking if our Multiple LR class works for single feature and target as in simple LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd6697de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"E:\\Jupyter Notebooks\\regression data placement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f08e030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.89</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.12</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.82</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.42</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.94</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  package\n",
       "0  6.89     3.26\n",
       "1  5.12     1.98\n",
       "2  7.82     3.25\n",
       "3  7.42     3.67\n",
       "4  6.94     3.57"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8dda7240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7730984312051702"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(df[['cgpa']], df.package, test_size=0.2,random_state=42)\n",
    "\n",
    "lr = LR()\n",
    "lr.fit(xtrain, ytrain)\n",
    "ypred = lr.predict(xtest)\n",
    "r2_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3acc7bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>6.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cgpa\n",
       "79   7.18\n",
       "197  7.21\n",
       "38   8.62\n",
       "24   6.53\n",
       "122  5.12\n",
       "..    ...\n",
       "106  6.13\n",
       "14   7.73\n",
       "92   7.90\n",
       "179  7.14\n",
       "102  5.13\n",
       "\n",
       "[160 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain#.shape, xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6cf8a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 7.18],\n",
       "       [1.  , 7.21],\n",
       "       [1.  , 8.62],\n",
       "       [1.  , 6.53],\n",
       "       [1.  , 5.12],\n",
       "       [1.  , 6.93],\n",
       "       [1.  , 7.15],\n",
       "       [1.  , 7.48],\n",
       "       [1.  , 4.85],\n",
       "       [1.  , 7.61],\n",
       "       [1.  , 5.84],\n",
       "       [1.  , 6.75],\n",
       "       [1.  , 7.89],\n",
       "       [1.  , 5.91],\n",
       "       [1.  , 7.12],\n",
       "       [1.  , 8.44],\n",
       "       [1.  , 7.91],\n",
       "       [1.  , 7.69],\n",
       "       [1.  , 6.93],\n",
       "       [1.  , 7.11],\n",
       "       [1.  , 9.31],\n",
       "       [1.  , 5.98],\n",
       "       [1.  , 8.1 ],\n",
       "       [1.  , 8.94],\n",
       "       [1.  , 6.87],\n",
       "       [1.  , 7.39],\n",
       "       [1.  , 5.95],\n",
       "       [1.  , 8.11],\n",
       "       [1.  , 7.11],\n",
       "       [1.  , 5.64],\n",
       "       [1.  , 9.26],\n",
       "       [1.  , 6.78],\n",
       "       [1.  , 5.53],\n",
       "       [1.  , 6.89],\n",
       "       [1.  , 7.4 ],\n",
       "       [1.  , 6.94],\n",
       "       [1.  , 8.31],\n",
       "       [1.  , 7.19],\n",
       "       [1.  , 7.95],\n",
       "       [1.  , 5.42],\n",
       "       [1.  , 7.82],\n",
       "       [1.  , 8.99],\n",
       "       [1.  , 6.07],\n",
       "       [1.  , 6.26],\n",
       "       [1.  , 7.28],\n",
       "       [1.  , 4.79],\n",
       "       [1.  , 7.3 ],\n",
       "       [1.  , 5.99],\n",
       "       [1.  , 6.19],\n",
       "       [1.  , 5.48],\n",
       "       [1.  , 6.14],\n",
       "       [1.  , 6.76],\n",
       "       [1.  , 6.71],\n",
       "       [1.  , 6.35],\n",
       "       [1.  , 6.61],\n",
       "       [1.  , 7.89],\n",
       "       [1.  , 8.71],\n",
       "       [1.  , 6.73],\n",
       "       [1.  , 5.42],\n",
       "       [1.  , 5.23],\n",
       "       [1.  , 6.94],\n",
       "       [1.  , 6.96],\n",
       "       [1.  , 6.93],\n",
       "       [1.  , 5.84],\n",
       "       [1.  , 7.77],\n",
       "       [1.  , 6.17],\n",
       "       [1.  , 5.32],\n",
       "       [1.  , 6.34],\n",
       "       [1.  , 8.58],\n",
       "       [1.  , 6.07],\n",
       "       [1.  , 8.6 ],\n",
       "       [1.  , 6.89],\n",
       "       [1.  , 7.63],\n",
       "       [1.  , 7.94],\n",
       "       [1.  , 5.79],\n",
       "       [1.  , 5.1 ],\n",
       "       [1.  , 7.36],\n",
       "       [1.  , 5.09],\n",
       "       [1.  , 8.93],\n",
       "       [1.  , 5.94],\n",
       "       [1.  , 9.38],\n",
       "       [1.  , 7.76],\n",
       "       [1.  , 6.98],\n",
       "       [1.  , 7.38],\n",
       "       [1.  , 7.28],\n",
       "       [1.  , 6.19],\n",
       "       [1.  , 7.88],\n",
       "       [1.  , 5.66],\n",
       "       [1.  , 6.1 ],\n",
       "       [1.  , 7.43],\n",
       "       [1.  , 8.65],\n",
       "       [1.  , 5.84],\n",
       "       [1.  , 5.83],\n",
       "       [1.  , 7.08],\n",
       "       [1.  , 7.66],\n",
       "       [1.  , 7.91],\n",
       "       [1.  , 7.42],\n",
       "       [1.  , 6.66],\n",
       "       [1.  , 6.47],\n",
       "       [1.  , 6.05],\n",
       "       [1.  , 6.19],\n",
       "       [1.  , 8.15],\n",
       "       [1.  , 6.31],\n",
       "       [1.  , 8.87],\n",
       "       [1.  , 7.63],\n",
       "       [1.  , 7.34],\n",
       "       [1.  , 6.75],\n",
       "       [1.  , 8.18],\n",
       "       [1.  , 6.22],\n",
       "       [1.  , 8.44],\n",
       "       [1.  , 6.29],\n",
       "       [1.  , 8.22],\n",
       "       [1.  , 6.42],\n",
       "       [1.  , 6.09],\n",
       "       [1.  , 6.93],\n",
       "       [1.  , 7.56],\n",
       "       [1.  , 8.01],\n",
       "       [1.  , 6.37],\n",
       "       [1.  , 5.38],\n",
       "       [1.  , 7.78],\n",
       "       [1.  , 7.04],\n",
       "       [1.  , 7.2 ],\n",
       "       [1.  , 8.13],\n",
       "       [1.  , 7.28],\n",
       "       [1.  , 9.16],\n",
       "       [1.  , 6.86],\n",
       "       [1.  , 6.33],\n",
       "       [1.  , 9.58],\n",
       "       [1.  , 5.89],\n",
       "       [1.  , 6.92],\n",
       "       [1.  , 8.63],\n",
       "       [1.  , 4.73],\n",
       "       [1.  , 6.85],\n",
       "       [1.  , 6.6 ],\n",
       "       [1.  , 7.13],\n",
       "       [1.  , 8.25],\n",
       "       [1.  , 7.29],\n",
       "       [1.  , 5.9 ],\n",
       "       [1.  , 6.47],\n",
       "       [1.  , 4.57],\n",
       "       [1.  , 5.12],\n",
       "       [1.  , 8.37],\n",
       "       [1.  , 8.28],\n",
       "       [1.  , 6.68],\n",
       "       [1.  , 6.12],\n",
       "       [1.  , 7.05],\n",
       "       [1.  , 6.61],\n",
       "       [1.  , 9.04],\n",
       "       [1.  , 8.09],\n",
       "       [1.  , 6.85],\n",
       "       [1.  , 6.5 ],\n",
       "       [1.  , 6.22],\n",
       "       [1.  , 7.28],\n",
       "       [1.  , 7.35],\n",
       "       [1.  , 7.47],\n",
       "       [1.  , 6.13],\n",
       "       [1.  , 7.73],\n",
       "       [1.  , 7.9 ],\n",
       "       [1.  , 7.14],\n",
       "       [1.  , 5.13]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(np.array(xtrain),0, 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87d963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
